{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d996732d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des bibliothèques nécessaires\n",
    "from playwright.sync_api import sync_playwright\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951acbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction principale\n",
    "def scrape_oddsportal():\n",
    "    with sync_playwright() as p:\n",
    "        # Lancement du navigateur en mode headless\n",
    "        browser = p.chromium.launch(headless=True)\n",
    "        context = browser.new_context(viewport={\"width\": 1920, \"height\": 1080})\n",
    "        page = context.new_page()\n",
    "\n",
    "        try:\n",
    "            # Chargement de l'URL cible\n",
    "            page.goto(\"https://www.oddsportal.com/value-bets/#1/0/overall\", wait_until=\"load\")\n",
    "            html = page.content()  # Récupération du contenu HTML\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Erreur lors du chargement de l'URL ou de la récupération du contenu HTML : {e}\")\n",
    "        finally:\n",
    "            browser.close()\n",
    "\n",
    "    # Analyse du contenu HTML avec BeautifulSoup\n",
    "    try:\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Erreur lors de l'analyse du contenu HTML : {e}\")\n",
    "\n",
    "    # Sélection de l'élément contenant les données\n",
    "    tabs = soup.select_one(\"div.tabs\")\n",
    "    if not tabs:\n",
    "        raise ValueError(\"Aucun élément 'div.tabs' trouvé dans le fichier HTML.\")\n",
    "\n",
    "    # Récupération des éléments visibles et cachés\n",
    "    try:\n",
    "        valuebets = tabs.select(\"div.visible\") + tabs.select(\"div.hidden\")\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Erreur lors de la récupération des éléments visibles et cachés : {e}\")\n",
    "\n",
    "    # Initialisation du dictionnaire pour stocker les données\n",
    "    data = {\n",
    "        'sports': [], 'countries': [], 'leagues': [], 'pronos': [],\n",
    "        'date': [], 'time': [], 'team_1': [], 'team_2': [],\n",
    "        'outcome': [], 'bookmaker': [], 'odds': [], 'value': [], \n",
    "        'probability': []\n",
    "    }\n",
    "\n",
    "    # Extraction des données des paris\n",
    "    for valuebet in valuebets:\n",
    "        try:\n",
    "            header = valuebet.select(\"a\")\n",
    "            data['sports'].append(header[0].text.strip() if len(header) > 0 else None)\n",
    "            data['countries'].append(header[1].text.strip() if len(header) > 1 else None)\n",
    "            data['leagues'].append(' '.join(header[2].text.split()) if len(header) > 2 else None)\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de l'extraction des données de l'en-tête : {e}\")\n",
    "\n",
    "    # Extraction des informations sur les matchs\n",
    "    match_info = tabs.find_all(\"div\", class_=\"flex min-h-[90px] w-full\")\n",
    "    for match in match_info:\n",
    "        try:\n",
    "            p_elements = match.select(\"p\")\n",
    "            match_data = [p.text.strip() for p in p_elements]\n",
    "            if len(match_data) >= 9:  # Vérification pour éviter les erreurs d'indice\n",
    "                data['pronos'].append(match_data[0])\n",
    "                data['date'].append(match_data[1])\n",
    "                data['time'].append(match_data[2])\n",
    "                data['team_1'].append(match_data[3])\n",
    "                data['team_2'].append(match_data[4])\n",
    "                data['outcome'].append(match_data[5])\n",
    "                data['odds'].append(match_data[6])\n",
    "                data['value'].append(match_data[7])\n",
    "                data['probability'].append(match_data[8])\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de l'extraction des informations sur les matchs : {e}\")\n",
    "\n",
    "    # Extraction des informations sur les bookmakers\n",
    "    bookmaker_info = tabs.find_all(\"div\", class_=\"h-[25px] w-[75px]\")\n",
    "    for bookmaker in bookmaker_info:\n",
    "        try:\n",
    "            img = bookmaker.find(\"img\")\n",
    "            data['bookmaker'].append(img['alt'] if img and 'alt' in img.attrs else None)\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de l'extraction des informations sur les bookmakers : {e}\")\n",
    "\n",
    "    # Création d'un DataFrame pandas à partir des données collectées\n",
    "    try:\n",
    "        df = pd.DataFrame(data)\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Erreur lors de la création du DataFrame : {e}\")\n",
    "\n",
    "    # Traitement des données\n",
    "    df['probability'] = pd.to_numeric(df['probability'].apply(lambda p: p.replace('%', '') if isinstance(p, str) else None), errors='coerce')\n",
    "    today = datetime.now()\n",
    "    df['date'] = df['date'].apply(lambda date: date.replace(',', '').replace(\"Tomorr.\", (today + timedelta(days=1)).strftime('%d %b')).replace(\"Today.\", today.strftime('%d %b')) if isinstance(date, str) else None)\n",
    "    current_year = today.year\n",
    "    df['date'] = df['date'].apply(lambda date: f\"{date} {current_year}\" if isinstance(date, str) else None)\n",
    "    df['date'] = pd.to_datetime(df['date'], format='%d %b %Y', errors='coerce')\n",
    "    df['time'] = pd.to_datetime(df['time'], format='%H:%M', errors='coerce').dt.strftime('%H:%M')\n",
    "    df['value'] = pd.to_numeric(df['value'], errors='coerce')\n",
    "    df['odds'] = pd.to_numeric(df['odds'], errors='coerce')\n",
    "    df.sort_values(by='probability', ascending=False, inplace=True)\n",
    "\n",
    "    # Sauvegarde des données dans un fichier CSV\n",
    "    try:\n",
    "        df.to_csv('oddsportal_data.csv', index=False)\n",
    "        print(\"Les données ont été sauvegardées avec succès dans 'oddsportal_data.csv'.\")\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Erreur lors de la sauvegarde des données dans un fichier CSV : {e}\")\n",
    "\n",
    "    # Affichage des 5 premières lignes\n",
    "    print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58da6919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exécution\n",
    "scrape_oddsportal()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
